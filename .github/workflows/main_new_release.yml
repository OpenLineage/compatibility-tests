name: Release check

on:
  schedule:
    - cron: "0 3 * * *"
  workflow_dispatch:
    inputs:
      run_dataplex:
        description: 'Run Dataplex tests'
        required: false
        default: 'true'
      run_spark_dataproc:
        description: 'Run Spark Dataproc tests'
        required: false
        default: 'true'
      openlineage_release:
        description: 'Override OpenLineage release version'
        required: false

permissions:
  id-token: write
  contents: write
  pull-requests: write
  issues: write

jobs:
  initialize_workflow:
    runs-on: ubuntu-latest
    outputs:
      run_dataplex: ${{ github.event.inputs.run_dataplex || 'true' }}
      run_spark_dataproc: ${{ github.event.inputs.run_spark_dataproc || 'true' }}
      openlineage_release: ${{ github.event.inputs.openlineage_release || steps.select-components.outputs.ol_release }}
      execution_time: ${{ steps.get-execution-time.outputs.execution_time }}
    steps:
      - name: Get execution time
        id: get-execution-time
        run: echo "execution_time=$(date +'%Y%d%m%H%M')" >> $GITHUB_OUTPUT

      - name: Checkout code
        uses: actions/checkout@v4

        # there should be part about checking not only the OL version but also the producers and consumers
        # there is no way to check for new releases of spark_dataproc or dataplex so we just run their tests everytime
        # also normally new release of OL should trigger all producer tests but for now they are run anyway so no need to trigger
      - name: Select components to run
        id: select-components
        run: ./scripts/select_components.sh
      - uses: actions/upload-artifact@v4
        if: steps.select-components.outputs.releases_updated == 'true'
        with:
          name: updated-releases
          path: generated-files/updated-releases.json
          retention-days: 1

  ######## COMPONENT VALIDATION ########

  dataplex:
    needs: initialize_workflow
    if: ${{ needs.initialize_workflow.outputs.run_dataplex == 'true' }}
    uses: ./.github/workflows/consumer_dataplex.yml
    secrets:
      gcpKey: ${{ secrets.GCP_SA_KEY }}
    with:
      release: ${{ needs.initialize_workflow.outputs.openlineage_release }}

  spark-dataproc:
    needs: initialize_workflow
    if: ${{ needs.initialize_workflow.outputs.run_spark_dataproc == 'true' }}
    uses: ./.github/workflows/producer_spark_dataproc.yml
    secrets:
      gcpKey: ${{ secrets.GCP_SA_KEY }}
      postgresqlUser: ${{ secrets.POSTGRESQL_USER }}
      postgresqlPassword: ${{ secrets.POSTGRESQL_PASSWORD }}
    with:
      release: ${{ needs.initialize_workflow.outputs.openlineage_release }}
      get-latest-snapshots: 'false'

  ######## COLLECTION OF REPORTS AND EXECUTE APPROPRIATE ACTIONS ########

  collect-and-compare-reports:
    needs:
      - initialize_workflow
      - dataplex
      - spark-dataproc
    if: ${{ !failure() }}
    uses: ./.github/workflows/collect_and_compare_reports.yml

  notify-maintainers:
    needs:
      - initialize_workflow
      - collect-and-compare-reports
    if: ${{ !failure() }}
    uses: ./.github/workflows/notify_maintainers.yml
    with:
      workflow-type: 'release'
      trigger-type: ${{ github.event.inputs.openlineage_release && 'manual' || 'scheduled' }}
      execution-time: ${{ needs.initialize_workflow.outputs.execution_time }}

  generate-compatibility-tables:
    needs: collect-and-compare-reports
    if: ${{ !failure() }}
    uses: ./.github/workflows/generate_compatibility_tables.yml

  update-repo-files:
    needs:
      - initialize_workflow
      - notify-maintainers
      - generate-compatibility-tables
    if: ${{ !failure() }}
    uses: ./.github/workflows/update_repo_files.yml
    with:
     workflow-type: 'release'
     trigger-type: ${{ github.event.inputs.openlineage_release && 'manual' || 'scheduled' }}
     execution-time: ${{ needs.initialize_workflow.outputs.execution_time }}